{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_txt = []\n",
    "exp_txt.append('안녕하세요. \\n \\\n",
    "빅데이터반(유연수 선생님) \\n \\\n",
    "8기 정성호 입니다.')\n",
    "exp_txt.append('지금부터는 CNN 뉴스 데이터의 번역 코드를 동영상으로 시연하도록 하겠습니다.')\n",
    "exp_txt.append('오랜시간 반복되는 작업 이기 때문에 지금부터 코드구현을 리스트 원소 10개 분량으로 짧게 시연하도록 하겠습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  urllib.request\n",
    "from  bs4  import  BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "binary = 'C:\\project\\chromedriver\\\\chromedriver.exe'\n",
    "browser = webdriver.Chrome(binary)\n",
    "browser.get(\"https://translate.google.co.kr/?hl=ko\")\n",
    "\n",
    "for i in exp_txt:\n",
    "    browser.find_element_by_id(\"source\").send_keys(i)\n",
    "    time.sleep(5)\n",
    "    browser.find_element_by_id(\"source\").clear()\n",
    "    time.sleep(1)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "params = []\n",
    "f = open('c:\\project\\chosunNews.txt', 'w', encoding = 'UTF-8')\n",
    "for i in range(1, 225):\n",
    "    list_url = \"http://search.chosun.com/search/news.search?query=%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0&pageno=\"+ str(i) + \"&orderby=docdatetime&naviarraystr=&kind=&cont1=&cont2=&cont5=&categoryname=&categoryd2=&c_scope=paging&sdate=&edate=&premium=\"\n",
    "    url = urllib.request.Request(list_url)\n",
    "    result = urllib.request.urlopen(url).read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup( result , \"html.parser\")\n",
    "    for j in soup.find_all('dd', class_='thumb'):\n",
    "        for i2 in j:\n",
    "            params.append(i2.get('href'))\n",
    "    time.sleep(1)    \n",
    "\n",
    "x = ''\n",
    "for i in params:\n",
    "    url = urllib.request.Request(i)\n",
    "    try:\n",
    "        result = urllib.request.urlopen(url).read().decode(\"euckr\")\n",
    "    except:\n",
    "        result = urllib.request.urlopen(url).read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup( result , \"html.parser\")\n",
    "    for i in soup.find_all('div', class_=\"par\"):\n",
    "        if x != i.get_text():\n",
    "            x = i.get_text()\n",
    "            f.write('%s\\n' %x)\n",
    "        else:\n",
    "            pass\n",
    "    time.sleep(2)\n",
    "print('저장되었습니다.')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\t세계적 전기전자 기업 지멘스의 한국법인 지멘스(대표이사·사장 직무대행 럼추콩)가 고령화 사회에 대비한 실버 헬스케어 서비스 개발을 위해 한전KDN(대표 박성철) 및 오송첨단의료산업진흥재단(이사장 박구선)과 상호협력을 위한 업무협약을 체결했다고 지난 18일 밝혔다. 3사는 이번 업무 협약을 통해 스마트폰 또는 인터넷 서비스를 제공받지 못하는 ‘디지털 약자’인 실버계층을 대상으로 실버헬스케어 서비스를 공급한다. 지멘스는 클라우드 기반 개방형 IoT 운영 체제인 ‘마인드스피어(MindSphere)’를 통해 전력 사용정보 및 바이오헬스 데이터를 취합하고 분석하는 서비스를 개발할 예정이다. 한전KDN은 전력통신망 기술 및 유무선 혼복합 게이트웨이 기술을 제공하며 오송첨단의료산업진흥재단은 신체 활동 및 응급상황 모니터링이 가능한 웨어러블 디바이스를 개발하여 실버계층의 헬스케어 정보를 전송한다. \n",
      "\n",
      "\r\n",
      "\t주 협력분야는 △사회안전망 구축을 위한 전력통신 기반 실버헬스케어 기술개발 추진 △웨어러블 디바이스 개발 및 빅데이터 플랫폼 응용, 헬스케어 서비스 개발 △대국민서비스를 위한 실버 헬스케어 현장 실증 등이다. 지멘스 럼추콩 대표이사·사장은 “고령화 사회에 진입한 한국에서 ICT(정보통신기술) 기반 실버 헬스케어 분야는 가장 중요한 공공복지이자 미래형 산업이 될 것”이라며 “지멘스의 IoT 운영 체제 마인드스피어를 통해 실버계층의 건강정보를 수집·분석·예측하여 보다 높은 질의 헬스케어 서비스를 제공할 뿐 아니라 사이버 보안을 최우선하고 있는 만큼 민감한 개인정보의 안전 보장에 선도적 역할을 하고 지역사회와 고객 및 파트너와의 신뢰를 지속해 나갈 것”이라고 말했다. 이어 “지멘스는 4차 산업혁명 시대에 실버 헬스케어 산업의 디지털화를 소프트웨어, 스마트 시티 등 신성장동력 산업 분야로도 확대해 나갈 수 있도록 기여하겠다”고 덧붙였다. \r\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "list_url = \"http://senior.chosun.com/site/data/html_dir/2018/12/31/2018123180078.html\"\n",
    "url = urllib.request.Request(list_url)\n",
    "result = urllib.request.urlopen(url).read().decode(\"euckr\")\n",
    "soup = BeautifulSoup( result , \"html.parser\")\n",
    "for i in soup.find_all('div', class_=\"par\"):\n",
    "    print(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
